<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Posts :: chengzhycn&#39;s blog</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="https://chengzhycn.github.io/posts/" />





  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/fonts.min.176c65cdf7082e9866e90b1fa123c60056f6d985b7cd3c4235600dada719e971.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/main.min.0909aaaf12e6fc3cdf2758321db2805239dc85602baff9dc07ce57d3d7365095.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/terminal.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="https://chengzhycn.github.io/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="https://chengzhycn.github.io/favicon.png">
<link rel="apple-touch-icon" href="https://chengzhycn.github.io/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Posts">
<meta property="og:description" content="" />
<meta property="og:url" content="https://chengzhycn.github.io/posts/" />
<meta property="og:site_name" content="chengzhycn&#39;s blog" />

  <meta property="og:image" content="https://chengzhycn.github.io/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="chengzhycn&#39;s blog" />









</head>
<body>


<div class="container center">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    chengzhycn&#39;s blog
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/">Home</a></li>
        
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/posts/">Archives</a></li>
        
      
        
          <li><a href="/categories/">Categories</a></li>
        
      
        
          <li><a href="/tags/">Tags</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/" >Home</a></li>
        
      
        
          <li><a href="/about" >About</a></li>
        
      
      
        <li>
          <ul class="menu">
            <li class="menu__trigger">Show more&nbsp;▾</li>
            <li>
              <ul class="menu__dropdown">
                
                  
                    <li><a href="/posts/" >Archives</a></li>
                  
                
                  
                    <li><a href="/categories/" >Categories</a></li>
                  
                
                  
                    <li><a href="/tags/" >Tags</a></li>
                  
                
              </ul>
            </li>
          </ul>
        </li>
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="https://chengzhycn.github.io/posts/2025-08/kaist-cs431-safe-memory-reclamation/">KAIST-CS431: Safe Memory Reclamation</a>
        </h2>
        <div class="post-meta"><time class="post-date">2025-08-28</time></div>

        
          <span class="post-tags">
            
            #<a href="https://chengzhycn.github.io/tags/rust/">Rust</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/concurrency/">Concurrency</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/kaist-cs431/">KAIST-CS431</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>无锁数据结构和传统的数据结构在内存管理有一点区别是：当数据不用了，需要释放内存时，传统数据结构直接调用<code>free()</code>就可以了，但是无锁数据结构不行。举个例子，如下图所示，T1正在读取b1的时候，T2释放了b1，T1中的指针就变成了野指针，造成不安全的内存访问。</p>
<p><img src="/images/notes/kaist-cs431-safe-memory-reclamation/image-20220410114205442.png" alt="image-20220410114205442"></p>
<p>因此，在无锁数据结构中，内存的释放操作一般要延后执行，即保证没有线程能够访问到该片内存后，再执行内存回收。这种方式被称作Safe Memory Reclamation（SMR）。</p>
<p>从上述例子中，我们可以从两个方面去理解一个SMR算法：</p>
<ol>
<li><strong>如何保护正在使用的数据不被释放？</strong></li>
<li><strong>什么时候能安全地释放已经被标记为需要释放的内存？</strong></li>
</ol>
<p>下面介绍两种常用的SMR算法：</p>
<ol>
<li>Hazard Pointers（Protected Pointers）</li>
<li>Epoch-Based Reclamation（基于代际的内存释放）</li>
</ol>
<p><img src="/images/notes/kaist-cs431-safe-memory-reclamation/image-20220411074041712.png" alt="image-20220411074041712"></p>
<h2 id="hazard-pointers">Hazard Pointers</h2>
<p>Hazard Pointers的基本思想是<strong>线程访问数据块时会将指针记录下来，其它线程尝试释放内存时会感知到数据块引用的存在，从而延迟释放内存，直到所有线程对该数据块的访问结束。</strong></p>
<p><img src="/images/notes/kaist-cs431-safe-memory-reclamation/image-20220411083606925.png" alt="image-20220411083606925"></p>
<p>如上图所示，使用hazard pointers有如下几个步骤：</p>
<ol>
<li>在线程访问共享数据时，先调用<code>reserve()</code>方法，将指针记录在一个list内；</li>
<li>T2线程尝试释放释放b1时，调用<code>retire()</code>，因为检测到还有线程访问b1，延迟释放内存；</li>
<li>因为内存没有真正释放，T1能在b1 retire后继续访问b1。访问结束后，T1调用<code>unreserve()</code>将指针从list中移除；</li>
<li>T3调用<code>gc()</code>（可以周期性运行，也可以事件触发），遍历所有retired的数据块，如果list内没有指向数据块的指针，即可以真正回收内存。</li>
</ol>
<p>Hazard Pointers有些致命的缺点：</p>
<ol>
<li>不够快。因为<code>reserve()</code>保护的指针需要立即被<code>gc()</code>感知到，所以，两个函数都需要引入开销非常大的store-load fence。在遍历整个数据结构时，每个数据块都会调用<code>reserve()</code>，导致遍历效率降低；</li>
<li>并不是所有的数据结构都适用Hazard Pointers。在前文的Lock-free Linked List中，我们也提过Harris-Michael‘s traversing是为了专门支持Hazard Pointers的。Harris&rsquo;s traversing会retire一个连续的数据块，这样，即便T1线程保护了其中一个数据块，<code>gc()</code>仍然可以回收其它的数据块内存，T1线程访问next指针时，仍然会出现问题。</li>
</ol>
<h2 id="epoch-based-reclamation">Epoch-Based Reclamation</h2>
<p>Hazard Pointers只保护无锁数据结构中真正被访问的那部分数据，这也导致了上文中Hazard Pointers的两个缺陷。与Hazard Pointers不同的是，<strong>EBR保护的是数据结构中所有可能潜在的访问</strong>。这样也就不需要频繁地在线程间同步。</p>
<p><img src="/images/notes/kaist-cs431-safe-memory-reclamation/image-20220413090336739.png" alt="image-20220413090336739"></p>
<p>每个线程在访问数据结构前都会开启一个代际（epoch）。T1在代际e中retire了b1和b2。那么什么时候能安全地reclaim b1和b2的内存呢？</p>
<p>如上图，我们在这个EBR算法中规定了一个<strong>代际一致性规则：并发的代际之间最多只能相差1。<strong>也就是说，只要T1还没有调用<code>set_quiescent()</code>结束掉e代，那么其它线程通过<code>set_active()</code>开启的代际号只能是e+1。而所有的e+1代的线程是有可能引用到b1和b2的。当e代结束，T2开启e+2代时，因为e+2代和e代不存在</strong>同时发生</strong>的可能性（通过代际一致性规则保证），所以在e+2代是不可能访问到e代retire的b1和b2的。到了e+3代，表示所有可能访问到b1和b2的e+1代都已经结束，此时即可安全地回收b1和b2内存。</p>
<p>不同的代际一致性规则，可以安全回收的代际是不一样的。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/posts/2025-08/kaist-cs431-safe-memory-reclamation/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="https://chengzhycn.github.io/posts/2025-08/kaist-cs431-concurrent-data-structure/">KAIST-CS431: Concurrent Data Structure</a>
        </h2>
        <div class="post-meta"><time class="post-date">2025-08-28</time></div>

        
          <span class="post-tags">
            
            #<a href="https://chengzhycn.github.io/tags/rust/">Rust</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/concurrency/">Concurrency</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/kaist-cs431/">KAIST-CS431</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <h2 id="并发数据结构的关键点">并发数据结构的关键点</h2>
<ul>
<li><strong>安全性：</strong> 安全是并发程序对CDS的最基本的要求
<ul>
<li>Sequential specification：多线程对数据结构的操作要能像一个队列一样</li>
<li>Synchronization：如在栈操作中，不同的线程进行pushing和popping操作时是要同步的，不能这边线程执行完了，另外一边无法感知到这边的操作。</li>
<li><strong>通过锁或者更加底层的同步原语来保护并发数据结构</strong></li>
</ul>
</li>
<li><strong>可扩展性：</strong> 随着CPU核数/并发度的增长，有着良好的性能增长
<ul>
<li>理想情况下，性能增长应该是线性的，但现实情况往往因为各种限制因素达不到线性增长</li>
<li><strong>通过减少锁保护范围（更细粒度的锁）来减少竞争</strong>
<ul>
<li>hand-over-hand locking, lock coupling, read-write locking</li>
</ul>
</li>
<li><strong>通过避免写操作降低缓存失效</strong></li>
</ul>
</li>
<li><strong>Progress:</strong> guaranteeing the completion (or progress) of operations
<ul>
<li>Lock freedom: progress of at least one</li>
<li>Wait freedom: progress of everyone</li>
</ul>
</li>
</ul>
<h2 id="无锁策略">无锁策略</h2>
<p>Lock-Free 和 Wait-Free 都旨在解决传统锁（如互斥锁 mutex）带来的性能和活性问题，但采用了不同的策略和提供了不同的保证。</p>
<h3 id="lock-free">Lock-Free</h3>
<p>Lock-Free 是一个相对较弱的保证，但仍然非常强大和有用。它的核心思想是：<strong>总会有一个线程能够前进，即使其他线程被任意延迟或阻塞。</strong></p>
<p><strong>核心特点：</strong></p>
<ul>
<li><strong>没有死锁 (Deadlock-Free)：</strong> 由于没有线程需要等待其他线程释放锁，所以不会发生死锁。</li>
<li><strong>没有活锁 (Livelock-Free)：</strong> 虽然有可能发生活锁（即线程反复尝试但总是失败），但通常通过回退策略（如指数退避）或设计良好的原子操作序列可以避免。然而，严格意义上的 Lock-Free 并不直接保证 Livelock-Free。</li>
<li><strong>进度保证 (Progress Guarantee)：</strong> 只要系统不是完全停滞，总有一个或多个线程可以完成操作。这意味着整个系统的吞吐量不会因为某个线程的无限期暂停而归零。</li>
<li><strong>饥饿可能 (Starvation Possible)：</strong> 某个特定的线程可能会无限期地重试它的操作，而从未成功（即所谓的“饥饿”）。这是 Lock-Free 与 Wait-Free 的一个主要区别。</li>
<li><strong>实现方式：</strong> 主要依赖于原子操作，如<code>CAS (Compare-And-Swap)</code>，<code>FAA (Fetch-And-Add)</code>，<code>LL/SC (Load-Link/Store-Conditional)</code>等。这些操作通常由硬件提供，能够以原子方式读取、修改和写入内存位置，而无需使用操作系统级别的锁。</li>
<li><strong>常见数据结构：</strong> 无锁队列 (Lock-Free Queue)，无锁栈 (Lock-Free Stack)，无锁哈希表 (Lock-Free Hash Table) 等。</li>
</ul>
<p><strong>工作原理示例（CAS）：</strong></p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/posts/2025-08/kaist-cs431-concurrent-data-structure/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="https://chengzhycn.github.io/posts/2025-08/kaist-cs431-lock-implementations/">KAIST-CS431: Lock Implementations</a>
        </h2>
        <div class="post-meta"><time class="post-date">2025-08-28</time></div>

        
          <span class="post-tags">
            
            #<a href="https://chengzhycn.github.io/tags/rust/">Rust</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/concurrency/">Concurrency</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/kaist-cs431/">KAIST-CS431</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <h2 id="naive-spin-lock">Naive Spin Lock</h2>
<p><img src="/images/notes/kaist-cs431-lock-implementations/image-20220324081153922.png" alt="image-20220324081153922"></p>
<h3 id="naive-spin-lock的缺陷">Naive Spin Lock的缺陷</h3>
<ul>
<li>无法保证公平性，可能有的倒霉蛋空转了一辈子也无法cas成功，无法做到按竞争线程先来后到的次序占有锁。</li>
<li>扩展性差，大量对同一内存区域的自旋引发性能问题。</li>
</ul>
<h2 id="对naive-spin-lock的优化">对Naive Spin Lock的优化</h2>
<p>关键思路：</p>
<ul>
<li>通过release/acquire同步机制保证互斥量的排他性
<ul>
<li>从一个临界区的结束（release）到另一个临界区的开始（acquire）</li>
<li>在ticket lock里面是<code>curr</code>成员，CLH/MCS lock是每个waiter的一个新内存区域</li>
</ul>
</li>
<li>通过排队和等待不同的区域释放保证公平性
<ul>
<li>通过公平的指令来排队（如swap, fetch-and-add）</li>
<li>Ticket lock：通过<code>next</code>来排队，<code>curr</code>来等待锁</li>
<li>CLH/MCS lock：通过<code>tail</code>来排队，等待每个锁调用者申请的不同区域中值的变化来获取锁</li>
</ul>
</li>
</ul>
<h3 id="ticket-lock">Ticket Lock</h3>
<p><img src="/images/notes/kaist-cs431-lock-implementations/image-20220323075751550.png" alt="image-20220323075751550"></p>
<p>ticket lock在锁的结构体里面新增了一个原子变量<code>next</code>，每次需要竞争锁时，需要先从<code>next</code>中拿到一个ticket，然后再去监听<code>curr</code>，只有<code>curr</code>被更新成当前的ticket值后，才能去占领锁。</p>
<h4 id="优点">优点</h4>
<ul>
<li>利用公平指令排队解决了公平性问题</li>
</ul>
<h4 id="缺点">缺点</h4>
<ul>
<li>API相对较复杂（调用者感知ticket）（为什么不直接用curr+1？）</li>
<li>没有解决spinlock中所有线程监听同一个原子变量的问题</li>
</ul>
<h3 id="clh-lock">CLH Lock</h3>
<p><img src="/images/notes/kaist-cs431-lock-implementations/image-20220323082114800.png" alt="image-20220323082114800"></p>
<p>为了减少缓存一致性带来的开销，CLH lock被发明了。CLH是三个人首字母的缩写：Craig, Landin, and Hagersten。</p>
<p>CLH lock给所有等待线程分配了一个Node，每个Node初始为true，在锁内维护一个链表，所有竞争锁的线程都会获取到前一个线程的Node，并将<code>tail</code>指针指向自己的Node。</p>
<p>不同于spin lock和Ticket lock，CLH lock的临界区是前一个Node中的原子变量。在锁释放时，当前线程会将自己的Node值置为false，而排队的下一个线程监听到这个变化，则可以安全地占有锁了。</p>
<h4 id="优点-1">优点</h4>
<ul>
<li>线程监听的不同临界区，减少缓存一致性的开销</li>
<li>链表排队，也能保证公平性</li>
</ul>
<h4 id="缺点-1">缺点</h4>
<ul>
<li>O(n)的空间复杂度开销，n是临界区数目</li>
<li>每个线程都是在前驱节点的Node上自旋，如果跨NUMA会有性能问题</li>
</ul>
<h3 id="mcs-lock">MCS Lock</h3>
<p><img src="/images/notes/kaist-cs431-lock-implementations/image-20220324080334262.png" alt="image-20220324080334262"></p>
<p>MCS lock也是以三个人名命名的：John M. Mellor-Crummey and Michael L. Scott。MCS lock和LCH lock最大的不同是：CLH lock是在前驱节点上自旋，MCS则是在自己节点上自旋。</p>
<p>在CLH的Node结构里面，MCS又添加了一个<code>next</code>字段，新的线程竞争锁时，会将自己的Node添加到前驱节点的<code>next</code>字段中。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/posts/2025-08/kaist-cs431-lock-implementations/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="https://chengzhycn.github.io/posts/2025-08/kaist-cs431-promising-semantics/">KAIST-CS431: Promising Semantics</a>
        </h2>
        <div class="post-meta"><time class="post-date">2025-08-27</time></div>

        
          <span class="post-tags">
            
            #<a href="https://chengzhycn.github.io/tags/rust/">Rust</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/concurrency/">Concurrency</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/kaist-cs431/">KAIST-CS431</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本章是基于作者的研究“Promising semantics”: <a href="https://sf.snu.ac.kr/promise-concurrency/">https://sf.snu.ac.kr/promise-concurrency/</a> ，提出的一种对宽松内存（relaxed-memory）并发的建模方法。</p>
<p>主要观点有4个：</p>
<ul>
<li>modeling load hoisting w/ <strong>multi-valued memory</strong>
<ul>
<li>允许一个线程从某个位置读取到一个旧值</li>
</ul>
</li>
<li>modeling read-modify-write w/ <strong>message adjacency</strong>
<ul>
<li>禁止对单个值同时进行多个read-modify-write操作</li>
</ul>
</li>
<li>modeling coherence &amp; ordering w/ <strong>views</strong>
<ul>
<li>限制线程的行为</li>
</ul>
</li>
<li>modeling store hoisting w/ <strong>promises</strong>
<ul>
<li>Allowing a thread to speculatively write a value</li>
</ul>
</li>
</ul>
<p>个人理解，**即便是编译器/硬件的指令重排，也是需要遵循一定的规则的，不能随意乱排。**作者从值读取、存储、read-modify-write多种角度对线程的行为进行了建模，是为了解释哪些情况下出现多线程执行出现哪些结果是可能的，哪些是不被允许的。</p>
<p>hoisting load/store在网上没有搜到解释，但是有个gcc的优化提到了这个概念。大概意思时将存值/取值操作从原先的指令顺序中调整位置，优化执行效率。</p>
<p><a href="https://gcc.gnu.org/news/hoist.html">Load/Store Hoisting - GNU Project</a></p>
<h2 id="multi-value-memory">multi-value memory</h2>
<p>内存是一系列消息（message）所在的位置，而消息可以看作是<strong>值和时间戳</strong>的组合。线程很有可能在读取时从内存中读到一个旧值。（effectively hoisting loads）</p>
<p><img src="/images/notes/kaist-cs431-promising-semantics/image-20220318080820894.png" alt="image-20220318080820894"></p>
<p>在作者举的例子中，r1=r2=0是被允许的，因为r1 r2都有可能从Y X中读到一个旧值。从后文的view角度理解，因为在独立的线程中，X和Y的赋值并没有改变当前线程中相应Y和X的view，所以，r1 r2的读取操作是可以读到旧值的。</p>
<h2 id="message-adjacency">message adjacency</h2>
<p>上面说了，消息是值和时间戳范围的组合。read-modify-write操作修改了消息的值，在时间轴上应该和前值紧邻在一起（no gap）。</p>
<p><img src="/images/notes/kaist-cs431-promising-semantics/image-20220318081606125.png" alt="image-20220318081606125"></p>
<p>可以看到，两次fetch_add操作后，从X的视角上看，0、1、2是紧邻的。第二次fetch_add操作，只能紧贴着1操作，而不能插到0和1之间。</p>
<h2 id="views">views</h2>
<p>这个semantics对我是启发性最强的一章。</p>
<p>multi-valued memory允许了太多不在预期中的行为，因此我们需要做些限制，保证一致性和同步。</p>
<p>View分为三种，分别是：</p>
<ul>
<li>Per-thread view：一致性</li>
<li>Per-message view：release/acquire同步</li>
<li>Global view：SC同步</li>
</ul>
<h3 id="per-thread-view">Per-thread view</h3>
<p>Per-thread view表示线程对消息的确认。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/posts/2025-08/kaist-cs431-promising-semantics/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="https://chengzhycn.github.io/posts/2025-08/kaist-cs431-nondeterminisms-of-shared-memory-concurrency/">KAIST-CS431: Nondeterminisms of Shared-memory Concurrency</a>
        </h2>
        <div class="post-meta"><time class="post-date">2025-08-27</time></div>

        
          <span class="post-tags">
            
            #<a href="https://chengzhycn.github.io/tags/rust/">Rust</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/concurrency/">Concurrency</a>&nbsp;
            
            #<a href="https://chengzhycn.github.io/tags/kaist-cs431/">KAIST-CS431</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <h2 id="nondeterminism">Nondeterminism</h2>
<h3 id="thread-interleaving">thread interleaving</h3>
<p><strong>interleaving semantics：</strong> 将多线程的指令交替组合成好像是单线程执行一样。</p>
<p>不同线程间的Load/store指令是穿插执行的，导致最终的行为有多种多样的可能。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">static</span><span class="w"> </span><span class="no">COUNTER</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">AtomicUsize</span>::<span class="n">new</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">// thread A &amp; B
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">let</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">COUNTER</span><span class="p">.</span><span class="n">load</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="no">COUNTER</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">c</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w">
</span></span></span></code></pre></div><p>如上示例，两个线程A和B同时对COUNTER进行+1操作，预期结果当然是2。但是<strong>由于线程调度的不确定性</strong>可能出现如下的执行顺序：</p>
<pre tabindex="0"><code>[COUNTER=0] A load, B load, A store, B store [COUNTER=1]
</code></pre><p>导致结果不符合预期。</p>
<h4 id="解决方案">解决方案</h4>
<p>使用原子的reading &amp; writing，禁止掉这种不符预期的执行顺序。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="c1">// thread A &amp; B
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">let</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">COUNTER</span><span class="p">.</span><span class="n">fetch_and_add</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span><span class="w">
</span></span></span></code></pre></div><ul>
<li><strong>“Read-modify-write”</strong>, e.g. swap, compare-and-swap, fetch-and-add</li>
</ul>
<h3 id="reordering">reordering</h3>
<p><strong>同一个线程中的指令会因为硬件和编译器的优化发生指令重排。</strong></p>
<pre tabindex="0"><code>DATA = 42;       ||   if FLAG.load() {
FLAG.store(1);   ||       assert(DATA == 42);
                 ||   }
</code></pre><p>如上图示例，预期是当<code>FLAG.load()</code>为1时，<code>DATA == 42</code>。但是因为指令重排，左边线程中，<code>FLAG.store(1)</code>可能发生在赋值语句前面；右边线程中assert语句也可能发生在if语句前面。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/posts/2025-08/kaist-cs431-nondeterminisms-of-shared-memory-concurrency/">[Read more]</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
    
    
      <a href="/posts/page/2/" class="button inline next">
        [<span class="button__text">Older posts</span>] &gt;
      </a>
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/bundle.min.js"></script>





  
</div>

</body>
</html>
